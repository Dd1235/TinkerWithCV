{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88a54eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dedeepyaavancha/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fec4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.vision_transformer import vit_b_16, ViT_B_16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bae9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ViT base model with pretrained weights\n",
    "vit_model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1).cuda()\n",
    "vit_model.eval()\n",
    "\n",
    "# Freeze parameters\n",
    "for param in vit_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Use the built-in preprocessing\n",
    "transform = ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "# Storage\n",
    "class_labels = []\n",
    "y_true = []\n",
    "vit_features = []\n",
    "\n",
    "# Loop through test images (same as in your code)\n",
    "for classes in ['color', 'good', 'cut', 'hole', 'metal_contamination', 'thread']:\n",
    "    folder_path = base_path / \"test\" / classes\n",
    "\n",
    "    for pth in tqdm(folder_path.iterdir(), leave=False):\n",
    "        class_label = pth.parts[-2]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_image = transform(Image.open(pth)).cuda().unsqueeze(0)  # [1, 3, 224, 224]\n",
    "\n",
    "            # Extract CLS token\n",
    "            x = vit_model._process_input(test_image)\n",
    "            n = x.shape[0]\n",
    "            cls_token = vit_model.class_token.expand(n, -1, -1)\n",
    "            x = torch.cat((cls_token, x), dim=1)\n",
    "            x = vit_model.encoder(x)\n",
    "            cls_embedding = x[:, 0]  # [CLS] token â†’ shape: [1, 768]\n",
    "\n",
    "            vit_features.append(cls_embedding.squeeze().cpu().numpy())\n",
    "\n",
    "        class_labels.append(class_label)\n",
    "        y_true.append(0 if class_label == 'good' else 1)\n",
    "\n",
    "vit_features = np.array(vit_features)  # shape: [N_images, 768]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
